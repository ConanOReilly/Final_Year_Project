{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConanOReilly/Final_Year_Project/blob/main/Image_Data/ModelComparison_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcLJhFk00LEg"
      },
      "source": [
        "# **Image Classification Model Comparison**\n",
        "State-of-art, out-of-box CNNs and ViTs will be trained, evaluated and compared on the PAD-UFES-2020 dataset. The best performing model will be optimised and fine tuned.\n",
        "\n",
        "Models:\n",
        "*   DenseNet121\n",
        "*   ResNet50V2\n",
        "*   EfficientNetV2B0\n",
        "*   Swin-Tiny\n",
        "*   DeiT-Small\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdDPwuRW0LEi"
      },
      "source": [
        "# **Papers**\n",
        "\n",
        "\n",
        "*   Aljohani, Khalil, and Turki Turki. \"Automatic classification of melanoma skin cancer with deep convolutional neural networks.\" Ai 3.2 (2022): 512-525.\n",
        "*   Kreouzi M, Theodorakis N, Feretzakis G, Paxinou E, Sakagianni A, Kalles D, Anastasiou A, Verykios VS, Nikolaou M. Deep Learning for Melanoma Detection: A Deep Learning Approach to Differentiating Malignant Melanoma from Benign Melanocytic Nevi. Cancers (Basel). 2024 Dec 25;17(1):28. doi: 10.3390/cancers17010028. PMID: 39796659; PMCID: PMC11718884.\n",
        "*   Ozdemir, B., Pacal, I. A robust deep learning framework for multiclass skin cancer classification. Sci Rep 15, 4938 (2025).\n",
        "*   Shehzad, K.; Zhenhua, T.; Shoukat, S.; Saeed, A.; Ahmad, I.; Sarwar Bhatti, S.; Chelloug, S.A. A Deep-Ensemble-Learning-Based Approach for Skin Cancer Diagnosis. Electronics 2023, 12, 1342.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBhEP8e_0LEj",
        "outputId": "e5d9f1e2-ab68-4198-e119-d913569ffc3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD7MVBW_0LEk"
      },
      "source": [
        "# **Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u8lTXaB0LEl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuP6sZm80LEl",
        "outputId": "6de7bdfa-ae01-4e44-9c43-5362bcf823eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory growth set successfully.\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth set successfully.\")\n",
        "    except RuntimeError as e:\n",
        "        print(\"RuntimeError:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED3_0NTv0LEl"
      },
      "source": [
        "# **Preporcessing and Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8APFn1BO0LEm",
        "outputId": "b66ff65a-c8b4-461c-e427-fe60ca2496de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['ACK' 'BCC' 'MEL' 'NEV' 'SCC' 'SEK']\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "image_dir = \"/content/drive/MyDrive/Final Year Project/Data/PAD/imgs\"\n",
        "metadata_path = \"/content/drive/MyDrive/Final Year Project/Data/PAD/Metadata/metadata.csv\"\n",
        "\n",
        "# Load metadata\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "metadata_df[\"label_encoded\"] = label_encoder.fit_transform(metadata_df[\"diagnostic\"].str.upper())\n",
        "class_names = label_encoder.classes_\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# Image size\n",
        "img_size = 224\n",
        "\n",
        "# Unified transforms for training and validation\n",
        "unified_train_transforms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "unified_val_transforms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset\n",
        "class SkinCancerDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row[\"img_id\"])\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {img_path} | {e}\")\n",
        "            image = Image.new(\"RGB\", (224, 224))\n",
        "\n",
        "        label = row[\"label_encoded\"]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Split into train/val\n",
        "train_df, val_df = train_test_split(metadata_df, test_size=0.2, stratify=metadata_df[\"label_encoded\"], random_state=42)\n",
        "\n",
        "# Datasets\n",
        "train_dataset = SkinCancerDataset(train_df, image_dir, transform=unified_train_transforms)\n",
        "val_dataset = SkinCancerDataset(val_df, image_dir, transform=unified_val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM_8fXWY0LEm"
      },
      "source": [
        "# **Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9yuTOLZ0LEm"
      },
      "outputs": [],
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UlhgxJr0LEm"
      },
      "outputs": [],
      "source": [
        "# Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(metadata_df[\"label_encoded\"]),\n",
        "    y=metadata_df[\"label_encoded\"]\n",
        ")\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqMrD0WI0LEn"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiSa0CJx0LEn"
      },
      "outputs": [],
      "source": [
        "# Class weights as a tensor\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjICxKuC0LEn"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10,\n",
        "                scheduler=None, class_names=None, save_dir=\"./checkpoints\", model_name=\"model\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model.to(device)\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": []\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_path = os.path.join(save_dir, f\"{model_name}_best.pth\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        # Training loop\n",
        "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
        "        for inputs, labels in train_loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loop:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          torch.save(model.state_dict(), best_model_path)\n",
        "          print(f\"Saved new best model at epoch {epoch+1} with accuracy {val_acc:.4f}\")\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        # Print summary for the epoch\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "        print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    print(f\"\\nBest model saved to: {best_model_path}\")\n",
        "\n",
        "    return model, history, best_model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LKN68ME0LEn"
      },
      "source": [
        "**DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7K_Cbwk0LEn",
        "outputId": "3e7ea583-5557-4a4d-996c-3a6758adb15a",
        "colab": {
          "referenced_widgets": [
            "0f53dad85c1344aab03cd1bb7f7c650d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f53dad85c1344aab03cd1bb7f7c650d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load DenseNet121 from timm\n",
        "DenseNet121_model = timm.create_model(\"densenet121\", pretrained=True, num_classes=num_classes)\n",
        "DenseNet121_model.to(device)\n",
        "\n",
        "# Optimiser\n",
        "optimizer = optim.Adam(DenseNet121_model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFw0ZaJn0LEo",
        "outputId": "89b8e7d1-9936-4781-8d27-f978fd8b751d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.4293, Accuracy: 0.4266\n",
            "Val   Loss: 1.1138, Accuracy: 0.4957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.9703, Accuracy: 0.6317\n",
            "Val   Loss: 1.0412, Accuracy: 0.5217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.7621, Accuracy: 0.7035\n",
            "Val   Loss: 0.9123, Accuracy: 0.5826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.6258, Accuracy: 0.7372\n",
            "Val   Loss: 0.9794, Accuracy: 0.5957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.4636, Accuracy: 0.8058\n",
            "Val   Loss: 0.9961, Accuracy: 0.6761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.3899, Accuracy: 0.8243\n",
            "Val   Loss: 1.0949, Accuracy: 0.6913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.3718, Accuracy: 0.8531\n",
            "Val   Loss: 1.0406, Accuracy: 0.6348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.3486, Accuracy: 0.8634\n",
            "Val   Loss: 0.9829, Accuracy: 0.6652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.2677, Accuracy: 0.8896\n",
            "Val   Loss: 1.0953, Accuracy: 0.7000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.2284, Accuracy: 0.9162\n",
            "Val   Loss: 1.6442, Accuracy: 0.6913\n",
            "\n",
            "Best model saved to: /content/drive/MyDrive/Final Year Project/Code/Image Classification/DenseNet121/pytorch_densenet121_best.pth\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "trained_model, history, best_model_path = train_model(\n",
        "    model=DenseNet121_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    class_names=class_names,\n",
        "    save_dir=\"/content/drive/MyDrive/Final Year Project/Code/Image Classification/DenseNet121\",\n",
        "    model_name=\"pytorch_densenet121\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9icwRdS0LEo"
      },
      "source": [
        "**ResNet50V2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJNIsxIC0LEo",
        "outputId": "588eaa74-9288-4003-86d0-e11d73d6ff93",
        "colab": {
          "referenced_widgets": [
            "2f3d455ecc094562837cf1d0fcb1195e"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name resnetv2_50x1_bitm to current resnetv2_50x1_bit.goog_in21k_ft_in1k.\n",
            "  model = create_fn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f3d455ecc094562837cf1d0fcb1195e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load ResNet50V2 from timm\n",
        "ResNet50V2_model = timm.create_model(\"resnetv2_50x1_bitm\", pretrained=True, num_classes=num_classes)\n",
        "\n",
        "# Replace final head with your classifier if needed\n",
        "ResNet50V2_model.reset_classifier(num_classes=num_classes)\n",
        "ResNet50V2_model.to(device)\n",
        "\n",
        "# Optimiser\n",
        "optimizer = optim.Adam(ResNet50V2_model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahtOnyos0LEo",
        "outputId": "dafce78f-8186-436e-9f98-43146f4191e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.8050, Accuracy: 0.2797\n",
            "Val   Loss: 1.4615, Accuracy: 0.1848\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 1.4098, Accuracy: 0.3896\n",
            "Val   Loss: 1.3477, Accuracy: 0.4739\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 1.3208, Accuracy: 0.4695\n",
            "Val   Loss: 1.5090, Accuracy: 0.4565\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 1.1314, Accuracy: 0.5441\n",
            "Val   Loss: 1.0853, Accuracy: 0.4478\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 1.0318, Accuracy: 0.5152\n",
            "Val   Loss: 1.0685, Accuracy: 0.6043\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 1.1230, Accuracy: 0.5092\n",
            "Val   Loss: 1.0929, Accuracy: 0.3457\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.9178, Accuracy: 0.5555\n",
            "Val   Loss: 1.1017, Accuracy: 0.6022\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.8640, Accuracy: 0.6137\n",
            "Val   Loss: 1.0575, Accuracy: 0.4304\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.8537, Accuracy: 0.6268\n",
            "Val   Loss: 1.2076, Accuracy: 0.3413\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.8495, Accuracy: 0.6050\n",
            "Val   Loss: 1.1116, Accuracy: 0.6457\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1aca707e8161>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trained_model, history, best_model_path = train_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResNet50V2_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-773175bd6873>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, scheduler, class_names, save_dir, model_name)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Classification report & confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nClassification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ],
      "source": [
        "trained_model, history, best_model_path = train_model(\n",
        "    model=ResNet50V2_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    class_names=class_names,\n",
        "    save_dir=\"/content/drive/MyDrive/Final Year Project/Code/Image Classification/ResNet50V2\",\n",
        "    model_name=\"pytorch_resnet50v2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWvcYxTG0LEo"
      },
      "source": [
        "**EfficientNetV2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADW95LdU0LEo",
        "outputId": "78fc3b2a-dd23-4e7e-8fcd-9a74c764b50c",
        "colab": {
          "referenced_widgets": [
            "f1ed95c6f0b249c79c74c08444842103"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1ed95c6f0b249c79c74c08444842103",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load EfficientNetV2-S from timm\n",
        "EffNetV2S_model = timm.create_model(\"tf_efficientnetv2_s\", pretrained=True)\n",
        "EffNetV2S_model.reset_classifier(num_classes=num_classes)\n",
        "EffNetV2S_model.to(device)\n",
        "\n",
        "# Optimiser\n",
        "optimizer = optim.Adam(EffNetV2S_model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhYXEt0G0LEp",
        "outputId": "4682bc68-c591-4003-d02f-b42a85d248ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 1 with accuracy 0.5109\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.2048, Accuracy: 0.5131\n",
            "Val   Loss: 1.0194, Accuracy: 0.5109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 2 with accuracy 0.5891\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.7272, Accuracy: 0.7111\n",
            "Val   Loss: 0.8842, Accuracy: 0.5891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 3 with accuracy 0.6370\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.4075, Accuracy: 0.8281\n",
            "Val   Loss: 0.9802, Accuracy: 0.6370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 4 with accuracy 0.7065\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.3625, Accuracy: 0.8466\n",
            "Val   Loss: 0.9402, Accuracy: 0.7065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.2589, Accuracy: 0.8857\n",
            "Val   Loss: 1.1787, Accuracy: 0.6674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 6 with accuracy 0.7239\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.1949, Accuracy: 0.9211\n",
            "Val   Loss: 1.3114, Accuracy: 0.7239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.2050, Accuracy: 0.9124\n",
            "Val   Loss: 1.0865, Accuracy: 0.7217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 8 with accuracy 0.7370\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.1283, Accuracy: 0.9543\n",
            "Val   Loss: 1.3851, Accuracy: 0.7370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.1207, Accuracy: 0.9559\n",
            "Val   Loss: 1.2388, Accuracy: 0.7304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.1168, Accuracy: 0.9516\n",
            "Val   Loss: 1.2635, Accuracy: 0.6913\n",
            "\n",
            "Best model saved to: /content/drive/MyDrive/Final Year Project/Code/Image Classification/EfficientNetV2/pytorch_efficientnetv2s_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "trained_model, history, best_model_path = train_model(\n",
        "    model=EffNetV2S_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    class_names=class_names,\n",
        "    save_dir=\"/content/drive/MyDrive/Final Year Project/Code/Image Classification/EfficientNetV2\",\n",
        "    model_name=\"pytorch_efficientnetv2s\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a47f_Ayp0LEp"
      },
      "source": [
        "**Swin Tiny**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPjnbK1Y0LEp",
        "outputId": "ffc4e988-43c7-46a6-fa55-af6782f117f7",
        "colab": {
          "referenced_widgets": [
            "a77b713c14f94bf087203b6d4699a38c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a77b713c14f94bf087203b6d4699a38c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load Swin Tiny from timm\n",
        "SwinTiny_model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=num_classes)\n",
        "SwinTiny_model.to(device)\n",
        "\n",
        "# Optimiser\n",
        "optimizer = optim.AdamW(SwinTiny_model.parameters(), lr=3e-4, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2ofvqIV0LEp",
        "outputId": "a0da7559-dfbf-4155-824a-ac9800bc190f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 1 with accuracy 0.3500\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.8334, Accuracy: 0.1850\n",
            "Val   Loss: 1.7709, Accuracy: 0.3500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 2 with accuracy 0.3630\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 1.7910, Accuracy: 0.1665\n",
            "Val   Loss: 1.7491, Accuracy: 0.3630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 1.7097, Accuracy: 0.2231\n",
            "Val   Loss: 1.6103, Accuracy: 0.2304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 4 with accuracy 0.3696\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 1.6508, Accuracy: 0.2987\n",
            "Val   Loss: 1.4695, Accuracy: 0.3696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 1.5968, Accuracy: 0.2845\n",
            "Val   Loss: 1.8240, Accuracy: 0.0913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 1.5865, Accuracy: 0.2709\n",
            "Val   Loss: 1.5034, Accuracy: 0.3196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 7 with accuracy 0.4413\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 1.4586, Accuracy: 0.3303\n",
            "Val   Loss: 1.3272, Accuracy: 0.4413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 1.4692, Accuracy: 0.3890\n",
            "Val   Loss: 1.4843, Accuracy: 0.3565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 9 with accuracy 0.5370\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 1.4307, Accuracy: 0.4157\n",
            "Val   Loss: 1.2829, Accuracy: 0.5370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 1.3749, Accuracy: 0.4091\n",
            "Val   Loss: 1.3416, Accuracy: 0.4978\n",
            "\n",
            "Best model saved to: /content/drive/MyDrive/Final Year Project/Code/Image Classification/Swin-Tiny/pytorch_swintiny_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "trained_model, history, best_model_path = train_model(\n",
        "    model=SwinTiny_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    class_names=class_names,\n",
        "    save_dir=\"/content/drive/MyDrive/Final Year Project/Code/Image Classification/Swin-Tiny\",\n",
        "    model_name=\"pytorch_swintiny\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMCng7gT0LEp"
      },
      "source": [
        "**DeiT-Small**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY2WJDCk0LEp",
        "outputId": "33aa486b-aed9-4b3b-e97b-1a3a59b73b73",
        "colab": {
          "referenced_widgets": [
            "66c6ff19655d467d9e65ee36c7a1c389"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66c6ff19655d467d9e65ee36c7a1c389",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load DeiT Small from timm\n",
        "DeiT_model = timm.create_model(\"deit_small_patch16_224\", pretrained=True, num_classes=num_classes)\n",
        "DeiT_model.to(device)\n",
        "\n",
        "# Optimiser\n",
        "optimizer = optim.AdamW(DeiT_model.parameters(), lr=3e-4, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOjA7KQW0LEq",
        "outputId": "2900ee9a-a4c9-45bc-be5b-e236a038c2fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 1 with accuracy 0.4239\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 1.7593, Accuracy: 0.2187\n",
            "Val   Loss: 1.4767, Accuracy: 0.4239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 2 with accuracy 0.6043\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 1.3499, Accuracy: 0.4630\n",
            "Val   Loss: 1.0742, Accuracy: 0.6043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 1.1928, Accuracy: 0.5501\n",
            "Val   Loss: 1.3057, Accuracy: 0.4326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 1.0928, Accuracy: 0.5783\n",
            "Val   Loss: 1.1530, Accuracy: 0.4043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.9267, Accuracy: 0.6175\n",
            "Val   Loss: 1.0439, Accuracy: 0.5848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.8847, Accuracy: 0.6387\n",
            "Val   Loss: 0.9921, Accuracy: 0.5630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.7409, Accuracy: 0.6861\n",
            "Val   Loss: 0.9668, Accuracy: 0.6043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 8 with accuracy 0.6152\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.6147, Accuracy: 0.7367\n",
            "Val   Loss: 1.0737, Accuracy: 0.6152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model at epoch 9 with accuracy 0.6500\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.7140, Accuracy: 0.7057\n",
            "Val   Loss: 1.1395, Accuracy: 0.6500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.6867, Accuracy: 0.7089\n",
            "Val   Loss: 0.9559, Accuracy: 0.6022\n",
            "\n",
            "Best model saved to: /content/drive/MyDrive/Final Year Project/Code/Image Classification/DeiT-Small/pytorch_deitsmall_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "trained_model, history, best_model_path = train_model(\n",
        "    model=DeiT_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    class_names=class_names,\n",
        "    save_dir=\"/content/drive/MyDrive/Final Year Project/Code/Image Classification/DeiT-Small\",\n",
        "    model_name=\"pytorch_deitsmall\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
